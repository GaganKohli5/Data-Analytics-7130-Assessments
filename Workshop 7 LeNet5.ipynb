{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EDbJWoO1yO8e"
      },
      "source": [
        "# Image Classification with CNN - LeNet5 architecture"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzQxqD6HyO8i"
      },
      "source": [
        "In this exercise, we will apply the LeNet5 algorithm to the Fashion MNIST dataset and improve your performances."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XFyVotRvyO8j"
      },
      "source": [
        "We will first download the data:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTHLyL1fyO8j",
        "outputId": "430abf7b-25ec-4724-b080-5d93a95d3db1",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28)"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "# TODO: Load the dataset\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# # # If your computer is slow, try to use a subset of data, e.g.\n",
        "# X_train = X_train[:10000]\n",
        "# y_train = y_train[:10000]\n",
        "# X_test = X_test[:2000]\n",
        "# y_test = y_test[:2000]\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8ShXIANyO8l"
      },
      "source": [
        "As you already know, this dataset contains 10 classes:\n",
        "* 0:\tT-shirt/top\n",
        "* 1:\tTrouser\n",
        "* 2:\tPullover\n",
        "* 3:\tDress\n",
        "* 4:\tCoat\n",
        "* 5:\tSandal\n",
        "* 6:\tShirt\n",
        "* 7:\tSneaker\n",
        "* 8:\tBag\n",
        "* 9:\tAnkle boot"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvNG0PbyO8l"
      },
      "source": [
        "You can have a look at some images if needed, even if you already know them."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 452
        },
        "id": "lnjqgv-GyO8m",
        "outputId": "0881b6d8-8e9c-4c6a-c74e-6c67253eb4c5",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# TODO: Explore the data, display some input images\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "label_class = ['top', 'trouser', 'pullover', 'dress', 'coat', 'sandal', 'shirt', 'sneaker', 'bag', 'ankle boot']\n",
        "\n",
        "idx = np.random.randint(X_train.shape[0])\n",
        "\n",
        "plt.imshow(X_train[idx], cmap='gray_r')\n",
        "plt.title(label_class[y_train[idx]])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdYH6XW1yO8n"
      },
      "source": [
        "Make the data preparation and preprocessing: scale and reshape the data, put the labels to the good shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "fjv8XMPByO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f49a07db-3f0d-49e1-da6f-de1d74c2d291"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 28, 28, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "# TODO: Make the data preparation\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "y_train_cat = to_categorical(y_train, num_classes=10)\n",
        "y_test_cat = to_categorical(y_test, num_classes=10)\n",
        "\n",
        "X_train_norm = X_train/255\n",
        "X_test_norm = X_test/255\n",
        "\n",
        "\n",
        "X_train_norm = X_train_norm.reshape(X_train_norm.shape[0], 28, 28, 1)\n",
        "X_test_norm = X_test_norm.reshape(X_test_norm.shape[0], 28, 28, 1)\n",
        "\n",
        "X_train_norm.shape #Should be (60000, 28, 28, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y9LKzxR9yO8o"
      },
      "source": [
        "Now build the LeNet5 architecture. You can reuse the one of the course, or try to build it by yourself.\n",
        "\n",
        "The architecture is the following:\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://drive.google.com/uc?export=view&id=1WteTU2FPIVMkBKmMxGpFm5OjsX-szTbB\">\n",
        "</p>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "GKyMFlL6yO8o",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd8cb74-5e2d-4039-8bae-df521df64b12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " C1 (Conv2D)                 (None, 26, 26, 6)         60        \n",
            "                                                                 \n",
            " S2 (MaxPooling2D)           (None, 13, 13, 6)         0         \n",
            "                                                                 \n",
            " C3 (Conv2D)                 (None, 11, 11, 16)        880       \n",
            "                                                                 \n",
            " S4 (MaxPooling2D)           (None, 5, 5, 16)          0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 400)               0         \n",
            "                                                                 \n",
            " C5 (Dense)                  (None, 120)               48120     \n",
            "                                                                 \n",
            " F5 (Dense)                  (None, 84)                10164     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                850       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 60074 (234.66 KB)\n",
            "Trainable params: 60074 (234.66 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# TODO: Build your model\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import MaxPooling2D, Conv2D, Flatten, Dense\n",
        "\n",
        "\n",
        "def lenet5():\n",
        "\n",
        "    model = Sequential()\n",
        "\n",
        "    # Layer C1\n",
        "    model.add(Conv2D(filters=6, name='C1', kernel_size=(3, 3), activation='relu', input_shape=(28,28,1)))\n",
        "    # Layer S2\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S2'))\n",
        "    # Layer C3\n",
        "    model.add(Conv2D(filters=16, name='C3', kernel_size=(3, 3), activation='relu'))\n",
        "    # Layer S4\n",
        "    model.add(MaxPooling2D(pool_size=(2, 2), name='S4'))\n",
        "    # Before going into layer C5, we flatten our units\n",
        "    model.add(Flatten())\n",
        "    # Layer C5\n",
        "    model.add(Dense(120, activation='relu', name='C5'))\n",
        "    # Layer F6\n",
        "    model.add(Dense(84, activation='relu', name='F5'))\n",
        "    # Output layer\n",
        "    model.add(Dense(units=10, activation = 'softmax'))\n",
        "\n",
        "    return model\n",
        "\n",
        "lenet5().summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1qBEauqyO8p"
      },
      "source": [
        "Now compile and fit your model on your training data. Since this is a multiclass classification, the loss is not `binary_crossentropy` anymore, but `categorical_crossentropy`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPL3aKnyyO8p",
        "outputId": "3352a870-a519-4b86-a488-d77b18006244",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "30/30 [==============================] - 6s 33ms/step - loss: 1.8111 - accuracy: 0.4776 - val_loss: 1.0291 - val_accuracy: 0.6585\n",
            "Epoch 2/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.7885 - accuracy: 0.7186 - val_loss: 0.6789 - val_accuracy: 0.7434\n",
            "Epoch 3/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.6158 - accuracy: 0.7646 - val_loss: 0.5925 - val_accuracy: 0.7742\n",
            "Epoch 4/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.5519 - accuracy: 0.7896 - val_loss: 0.5449 - val_accuracy: 0.7967\n",
            "Epoch 5/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.5130 - accuracy: 0.8071 - val_loss: 0.5201 - val_accuracy: 0.8033\n",
            "Epoch 6/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.4842 - accuracy: 0.8201 - val_loss: 0.5060 - val_accuracy: 0.8118\n",
            "Epoch 7/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4636 - accuracy: 0.8288 - val_loss: 0.4794 - val_accuracy: 0.8202\n",
            "Epoch 8/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4456 - accuracy: 0.8357 - val_loss: 0.4669 - val_accuracy: 0.8266\n",
            "Epoch 9/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.4344 - accuracy: 0.8400 - val_loss: 0.4625 - val_accuracy: 0.8277\n",
            "Epoch 10/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4201 - accuracy: 0.8471 - val_loss: 0.4419 - val_accuracy: 0.8397\n",
            "Epoch 11/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.4080 - accuracy: 0.8520 - val_loss: 0.4325 - val_accuracy: 0.8461\n",
            "Epoch 12/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3979 - accuracy: 0.8564 - val_loss: 0.4300 - val_accuracy: 0.8431\n",
            "Epoch 13/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3962 - accuracy: 0.8566 - val_loss: 0.4156 - val_accuracy: 0.8487\n",
            "Epoch 14/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3838 - accuracy: 0.8618 - val_loss: 0.4137 - val_accuracy: 0.8498\n",
            "Epoch 15/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3788 - accuracy: 0.8624 - val_loss: 0.4040 - val_accuracy: 0.8562\n",
            "Epoch 16/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.3714 - accuracy: 0.8659 - val_loss: 0.4054 - val_accuracy: 0.8532\n",
            "Epoch 17/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.3674 - accuracy: 0.8673 - val_loss: 0.3968 - val_accuracy: 0.8553\n",
            "Epoch 18/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.3564 - accuracy: 0.8714 - val_loss: 0.3885 - val_accuracy: 0.8594\n",
            "Epoch 19/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3534 - accuracy: 0.8724 - val_loss: 0.3834 - val_accuracy: 0.8615\n",
            "Epoch 20/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.3490 - accuracy: 0.8742 - val_loss: 0.3823 - val_accuracy: 0.8622\n",
            "Epoch 21/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.3489 - accuracy: 0.8733 - val_loss: 0.3857 - val_accuracy: 0.8595\n",
            "Epoch 22/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3408 - accuracy: 0.8766 - val_loss: 0.3802 - val_accuracy: 0.8631\n",
            "Epoch 23/100\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.3425 - accuracy: 0.8755 - val_loss: 0.3767 - val_accuracy: 0.8612\n",
            "Epoch 24/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.3368 - accuracy: 0.8780 - val_loss: 0.3675 - val_accuracy: 0.8687\n",
            "Epoch 25/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.3300 - accuracy: 0.8799 - val_loss: 0.3656 - val_accuracy: 0.8683\n",
            "Epoch 26/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.3276 - accuracy: 0.8821 - val_loss: 0.3598 - val_accuracy: 0.8687\n",
            "Epoch 27/100\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.3243 - accuracy: 0.8818 - val_loss: 0.3628 - val_accuracy: 0.8668\n",
            "Epoch 28/100\n",
            "30/30 [==============================] - 1s 32ms/step - loss: 0.3187 - accuracy: 0.8850 - val_loss: 0.3531 - val_accuracy: 0.8721\n",
            "Epoch 29/100\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.3168 - accuracy: 0.8850 - val_loss: 0.3561 - val_accuracy: 0.8692\n",
            "Epoch 30/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.3122 - accuracy: 0.8868 - val_loss: 0.3523 - val_accuracy: 0.8731\n",
            "Epoch 31/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.3117 - accuracy: 0.8874 - val_loss: 0.3472 - val_accuracy: 0.8729\n",
            "Epoch 32/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.3085 - accuracy: 0.8879 - val_loss: 0.3728 - val_accuracy: 0.8612\n",
            "Epoch 33/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.3055 - accuracy: 0.8887 - val_loss: 0.3431 - val_accuracy: 0.8740\n",
            "Epoch 34/100\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.3001 - accuracy: 0.8911 - val_loss: 0.3432 - val_accuracy: 0.8757\n",
            "Epoch 35/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.3000 - accuracy: 0.8917 - val_loss: 0.3405 - val_accuracy: 0.8787\n",
            "Epoch 36/100\n",
            "30/30 [==============================] - 1s 27ms/step - loss: 0.2950 - accuracy: 0.8939 - val_loss: 0.3356 - val_accuracy: 0.8796\n",
            "Epoch 37/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2960 - accuracy: 0.8929 - val_loss: 0.3373 - val_accuracy: 0.8775\n",
            "Epoch 38/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2928 - accuracy: 0.8939 - val_loss: 0.3394 - val_accuracy: 0.8770\n",
            "Epoch 39/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2928 - accuracy: 0.8935 - val_loss: 0.3422 - val_accuracy: 0.8767\n",
            "Epoch 40/100\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.2888 - accuracy: 0.8957 - val_loss: 0.3279 - val_accuracy: 0.8821\n",
            "Epoch 41/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2844 - accuracy: 0.8971 - val_loss: 0.3442 - val_accuracy: 0.8748\n",
            "Epoch 42/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2843 - accuracy: 0.8968 - val_loss: 0.3341 - val_accuracy: 0.8759\n",
            "Epoch 43/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2811 - accuracy: 0.8987 - val_loss: 0.3369 - val_accuracy: 0.8767\n",
            "Epoch 44/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2795 - accuracy: 0.8983 - val_loss: 0.3290 - val_accuracy: 0.8819\n",
            "Epoch 45/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2813 - accuracy: 0.8974 - val_loss: 0.3306 - val_accuracy: 0.8808\n",
            "Epoch 46/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2764 - accuracy: 0.8990 - val_loss: 0.3268 - val_accuracy: 0.8813\n",
            "Epoch 47/100\n",
            "30/30 [==============================] - 0s 12ms/step - loss: 0.2743 - accuracy: 0.9010 - val_loss: 0.3228 - val_accuracy: 0.8813\n",
            "Epoch 48/100\n",
            "30/30 [==============================] - 0s 13ms/step - loss: 0.2709 - accuracy: 0.9014 - val_loss: 0.3255 - val_accuracy: 0.8836\n",
            "Epoch 49/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2724 - accuracy: 0.9006 - val_loss: 0.3230 - val_accuracy: 0.8827\n",
            "Epoch 50/100\n",
            "30/30 [==============================] - 0s 14ms/step - loss: 0.2719 - accuracy: 0.9011 - val_loss: 0.3284 - val_accuracy: 0.8795\n",
            "Epoch 51/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2652 - accuracy: 0.9047 - val_loss: 0.3163 - val_accuracy: 0.8879\n",
            "Epoch 52/100\n",
            "30/30 [==============================] - 0s 16ms/step - loss: 0.2663 - accuracy: 0.9037 - val_loss: 0.3151 - val_accuracy: 0.8859\n",
            "Epoch 53/100\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.2647 - accuracy: 0.9031 - val_loss: 0.3163 - val_accuracy: 0.8850\n",
            "Epoch 54/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2632 - accuracy: 0.9046 - val_loss: 0.3109 - val_accuracy: 0.8860\n",
            "Epoch 55/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2617 - accuracy: 0.9059 - val_loss: 0.3231 - val_accuracy: 0.8792\n",
            "Epoch 56/100\n",
            "30/30 [==============================] - 1s 26ms/step - loss: 0.2589 - accuracy: 0.9062 - val_loss: 0.3121 - val_accuracy: 0.8862\n",
            "Epoch 57/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2611 - accuracy: 0.9045 - val_loss: 0.3147 - val_accuracy: 0.8866\n",
            "Epoch 58/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2546 - accuracy: 0.9071 - val_loss: 0.3158 - val_accuracy: 0.8843\n",
            "Epoch 59/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2542 - accuracy: 0.9082 - val_loss: 0.3173 - val_accuracy: 0.8835\n",
            "Epoch 60/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2572 - accuracy: 0.9053 - val_loss: 0.3142 - val_accuracy: 0.8859\n",
            "Epoch 61/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2500 - accuracy: 0.9100 - val_loss: 0.3149 - val_accuracy: 0.8848\n",
            "Epoch 62/100\n",
            "30/30 [==============================] - 1s 25ms/step - loss: 0.2489 - accuracy: 0.9100 - val_loss: 0.3095 - val_accuracy: 0.8885\n",
            "Epoch 63/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2505 - accuracy: 0.9086 - val_loss: 0.3086 - val_accuracy: 0.8896\n",
            "Epoch 64/100\n",
            "30/30 [==============================] - 1s 20ms/step - loss: 0.2492 - accuracy: 0.9095 - val_loss: 0.3036 - val_accuracy: 0.8931\n",
            "Epoch 65/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2436 - accuracy: 0.9121 - val_loss: 0.3077 - val_accuracy: 0.8899\n",
            "Epoch 66/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2438 - accuracy: 0.9118 - val_loss: 0.3048 - val_accuracy: 0.8910\n",
            "Epoch 67/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2491 - accuracy: 0.9091 - val_loss: 0.3063 - val_accuracy: 0.8875\n",
            "Epoch 68/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2460 - accuracy: 0.9103 - val_loss: 0.3085 - val_accuracy: 0.8847\n",
            "Epoch 69/100\n",
            "30/30 [==============================] - 1s 21ms/step - loss: 0.2401 - accuracy: 0.9130 - val_loss: 0.2986 - val_accuracy: 0.8914\n",
            "Epoch 70/100\n",
            "30/30 [==============================] - 1s 28ms/step - loss: 0.2370 - accuracy: 0.9139 - val_loss: 0.3076 - val_accuracy: 0.8895\n",
            "Epoch 71/100\n",
            "30/30 [==============================] - 1s 23ms/step - loss: 0.2407 - accuracy: 0.9114 - val_loss: 0.3008 - val_accuracy: 0.8913\n",
            "Epoch 72/100\n",
            "30/30 [==============================] - 1s 29ms/step - loss: 0.2372 - accuracy: 0.9139 - val_loss: 0.3095 - val_accuracy: 0.8880\n",
            "Epoch 73/100\n",
            "30/30 [==============================] - 1s 22ms/step - loss: 0.2398 - accuracy: 0.9121 - val_loss: 0.3017 - val_accuracy: 0.8921\n",
            "Epoch 74/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2355 - accuracy: 0.9141 - val_loss: 0.3006 - val_accuracy: 0.8934\n",
            "Epoch 75/100\n",
            "30/30 [==============================] - 1s 18ms/step - loss: 0.2348 - accuracy: 0.9139 - val_loss: 0.3027 - val_accuracy: 0.8922\n",
            "Epoch 76/100\n",
            "30/30 [==============================] - 1s 17ms/step - loss: 0.2306 - accuracy: 0.9152 - val_loss: 0.3016 - val_accuracy: 0.8920\n",
            "Epoch 77/100\n",
            "30/30 [==============================] - 1s 19ms/step - loss: 0.2322 - accuracy: 0.9152 - val_loss: 0.3088 - val_accuracy: 0.8872\n",
            "Epoch 78/100\n",
            "30/30 [==============================] - 0s 17ms/step - loss: 0.2330 - accuracy: 0.9153 - val_loss: 0.3057 - val_accuracy: 0.8901\n",
            "Epoch 79/100\n",
            "30/30 [==============================] - 0s 15ms/step - loss: 0.2270 - accuracy: 0.9166 - val_loss: 0.3013 - val_accuracy: 0.8916\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e3e2259f010>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "# TODO: Compile and fit your model\n",
        "import os\n",
        "\n",
        "# os.environ['KMP_DUPLICATE_LIB_OK']='True' #https://stackoverflow.com/questions/53014306/error-15-initializing-libiomp5-dylib-but-found-libiomp5-dylib-already-initial\n",
        "\n",
        "\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from tensorflow.keras.callbacks import TensorBoard\n",
        "\n",
        "model = lenet5()\n",
        "\n",
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Define now our callbacks\n",
        "# callbacks = [EarlyStopping(monitor='val_loss', patience=10), TensorBoard(log_dir='./keras-logs', histogram_freq=0, write_graph=True, write_images=True)]\n",
        "callbacks = [EarlyStopping(monitor='val_loss', patience=10)]\n",
        "\n",
        "# Finally fit the model\n",
        "model.fit(x=X_train_norm, y=y_train_cat, validation_data=(X_test_norm, y_test_cat), epochs=100, batch_size=2048, callbacks=callbacks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rf-SqjjOyO8q"
      },
      "source": [
        "Have a look at the tensorboard and see if it gives a deeper understanding of your model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k2FTj7TSyO8q"
      },
      "source": [
        "Compute then the accuracy of your model. Is it better than a regular MLP used before?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rPjJoMQZyO8q",
        "outputId": "0c022bd7-990b-43c5-fed3-21d8d550ca67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 14ms/step\n",
            "accuracy on train with NN: 0.9163666666666667\n",
            "accuracy on test with NN: 0.8916\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size = 1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1vulsgHiyO8q"
      },
      "source": [
        "We will now add image augmentation to improve our results, especially we will try to reduce overfitting this way.\n",
        "\n",
        "To do so, you can use `ImageDataGenerator` from Keras that makes all the work for you (including rescaling), with the following parameter:\n",
        "* `horizontal_flip=True`\n",
        "\n",
        "For more info about how the `ImageDataGenerator` works, you can check out [this article](https://www.pyimagesearch.com/2019/07/08/keras-imagedatagenerator-and-data-augmentation/).\n",
        "\n",
        "Begin by creating an object `ImageDataGenerator` with this parameter."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "ExecuteTime": {
          "end_time": "2020-08-19T11:58:37.442182Z",
          "start_time": "2020-08-19T11:58:37.438397Z"
        },
        "id": "pas-fMSIyO8q"
      },
      "outputs": [],
      "source": [
        "# TODO: Instantiate an ImageDataGenerator object\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "datagen = ImageDataGenerator(horizontal_flip=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k7nCnu9syO8r"
      },
      "source": [
        "Finally, you can train your model using this generator, with the method `fit_generator` of your model and the method `flow` of your `ImageDataGenerator`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zt6wXa3IyO8r",
        "outputId": "318037ec-e024-437f-c7dd-37ba5809c0b8",
        "scrolled": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-11-5da9cbf7d7d8>:3: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "58/58 [==============================] - 4s 53ms/step - loss: 0.4493 - accuracy: 0.8514 - val_loss: 0.3268 - val_accuracy: 0.8823\n",
            "Epoch 2/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.3069 - accuracy: 0.8897 - val_loss: 0.3144 - val_accuracy: 0.8891\n",
            "Epoch 3/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2914 - accuracy: 0.8950 - val_loss: 0.3005 - val_accuracy: 0.8928\n",
            "Epoch 4/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.2838 - accuracy: 0.8968 - val_loss: 0.3069 - val_accuracy: 0.8905\n",
            "Epoch 5/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2783 - accuracy: 0.8989 - val_loss: 0.3011 - val_accuracy: 0.8927\n",
            "Epoch 6/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2727 - accuracy: 0.9005 - val_loss: 0.3141 - val_accuracy: 0.8831\n",
            "Epoch 7/100\n",
            "58/58 [==============================] - 3s 51ms/step - loss: 0.2718 - accuracy: 0.9003 - val_loss: 0.2995 - val_accuracy: 0.8913\n",
            "Epoch 8/100\n",
            "58/58 [==============================] - 3s 49ms/step - loss: 0.2641 - accuracy: 0.9039 - val_loss: 0.2953 - val_accuracy: 0.8932\n",
            "Epoch 9/100\n",
            "58/58 [==============================] - 4s 62ms/step - loss: 0.2613 - accuracy: 0.9046 - val_loss: 0.3059 - val_accuracy: 0.8905\n",
            "Epoch 10/100\n",
            "58/58 [==============================] - 3s 54ms/step - loss: 0.2608 - accuracy: 0.9051 - val_loss: 0.2989 - val_accuracy: 0.8923\n",
            "Epoch 11/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2585 - accuracy: 0.9046 - val_loss: 0.2962 - val_accuracy: 0.8927\n",
            "Epoch 12/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.2546 - accuracy: 0.9064 - val_loss: 0.2904 - val_accuracy: 0.8954\n",
            "Epoch 13/100\n",
            "58/58 [==============================] - 3s 55ms/step - loss: 0.2526 - accuracy: 0.9077 - val_loss: 0.2962 - val_accuracy: 0.8901\n",
            "Epoch 14/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2510 - accuracy: 0.9083 - val_loss: 0.2969 - val_accuracy: 0.8921\n",
            "Epoch 15/100\n",
            "58/58 [==============================] - 3s 56ms/step - loss: 0.2485 - accuracy: 0.9089 - val_loss: 0.3035 - val_accuracy: 0.8876\n",
            "Epoch 16/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2452 - accuracy: 0.9105 - val_loss: 0.2979 - val_accuracy: 0.8924\n",
            "Epoch 17/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2487 - accuracy: 0.9082 - val_loss: 0.2925 - val_accuracy: 0.8936\n",
            "Epoch 18/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2451 - accuracy: 0.9099 - val_loss: 0.2930 - val_accuracy: 0.8944\n",
            "Epoch 19/100\n",
            "58/58 [==============================] - 4s 72ms/step - loss: 0.2409 - accuracy: 0.9116 - val_loss: 0.2980 - val_accuracy: 0.8921\n",
            "Epoch 20/100\n",
            "58/58 [==============================] - 4s 67ms/step - loss: 0.2394 - accuracy: 0.9118 - val_loss: 0.2851 - val_accuracy: 0.8956\n",
            "Epoch 21/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2406 - accuracy: 0.9112 - val_loss: 0.2852 - val_accuracy: 0.8967\n",
            "Epoch 22/100\n",
            "58/58 [==============================] - 3s 51ms/step - loss: 0.2369 - accuracy: 0.9136 - val_loss: 0.2859 - val_accuracy: 0.8976\n",
            "Epoch 23/100\n",
            "58/58 [==============================] - 3s 56ms/step - loss: 0.2340 - accuracy: 0.9137 - val_loss: 0.2858 - val_accuracy: 0.8972\n",
            "Epoch 24/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2327 - accuracy: 0.9139 - val_loss: 0.2881 - val_accuracy: 0.8958\n",
            "Epoch 25/100\n",
            "58/58 [==============================] - 3s 50ms/step - loss: 0.2349 - accuracy: 0.9120 - val_loss: 0.2839 - val_accuracy: 0.8997\n",
            "Epoch 26/100\n",
            "58/58 [==============================] - 3s 52ms/step - loss: 0.2319 - accuracy: 0.9141 - val_loss: 0.2900 - val_accuracy: 0.8963\n",
            "Epoch 27/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2329 - accuracy: 0.9147 - val_loss: 0.3124 - val_accuracy: 0.8855\n",
            "Epoch 28/100\n",
            "58/58 [==============================] - 3s 53ms/step - loss: 0.2272 - accuracy: 0.9159 - val_loss: 0.2867 - val_accuracy: 0.8976\n",
            "Epoch 29/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2212 - accuracy: 0.9188 - val_loss: 0.2809 - val_accuracy: 0.9011\n",
            "Epoch 30/100\n",
            "58/58 [==============================] - 3s 50ms/step - loss: 0.2262 - accuracy: 0.9169 - val_loss: 0.2874 - val_accuracy: 0.8951\n",
            "Epoch 31/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2277 - accuracy: 0.9159 - val_loss: 0.2832 - val_accuracy: 0.9009\n",
            "Epoch 32/100\n",
            "58/58 [==============================] - 3s 58ms/step - loss: 0.2198 - accuracy: 0.9195 - val_loss: 0.2915 - val_accuracy: 0.8949\n",
            "Epoch 33/100\n",
            "58/58 [==============================] - 3s 57ms/step - loss: 0.2195 - accuracy: 0.9192 - val_loss: 0.2804 - val_accuracy: 0.8978\n",
            "Epoch 34/100\n",
            "58/58 [==============================] - 3s 50ms/step - loss: 0.2201 - accuracy: 0.9182 - val_loss: 0.2855 - val_accuracy: 0.8963\n",
            "Epoch 35/100\n",
            "58/58 [==============================] - 3s 46ms/step - loss: 0.2154 - accuracy: 0.9207 - val_loss: 0.2760 - val_accuracy: 0.9013\n",
            "Epoch 36/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.2157 - accuracy: 0.9197 - val_loss: 0.2776 - val_accuracy: 0.8978\n",
            "Epoch 37/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.2130 - accuracy: 0.9208 - val_loss: 0.2809 - val_accuracy: 0.9004\n",
            "Epoch 38/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2127 - accuracy: 0.9209 - val_loss: 0.2956 - val_accuracy: 0.8949\n",
            "Epoch 39/100\n",
            "58/58 [==============================] - 3s 45ms/step - loss: 0.2163 - accuracy: 0.9197 - val_loss: 0.2837 - val_accuracy: 0.8981\n",
            "Epoch 40/100\n",
            "58/58 [==============================] - 3s 47ms/step - loss: 0.2103 - accuracy: 0.9218 - val_loss: 0.2817 - val_accuracy: 0.8983\n",
            "Epoch 41/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2107 - accuracy: 0.9222 - val_loss: 0.2858 - val_accuracy: 0.8998\n",
            "Epoch 42/100\n",
            "58/58 [==============================] - 4s 61ms/step - loss: 0.2070 - accuracy: 0.9239 - val_loss: 0.2796 - val_accuracy: 0.8976\n",
            "Epoch 43/100\n",
            "58/58 [==============================] - 3s 48ms/step - loss: 0.2048 - accuracy: 0.9244 - val_loss: 0.2812 - val_accuracy: 0.8993\n",
            "Epoch 44/100\n",
            "58/58 [==============================] - 4s 64ms/step - loss: 0.2090 - accuracy: 0.9228 - val_loss: 0.2798 - val_accuracy: 0.8988\n",
            "Epoch 45/100\n",
            "58/58 [==============================] - 3s 59ms/step - loss: 0.2085 - accuracy: 0.9226 - val_loss: 0.2780 - val_accuracy: 0.9015\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e3da12b7490>"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# TODO: train your model\n",
        "batch_size = 1024\n",
        "model.fit_generator(datagen.flow(X_train_norm, y_train_cat, batch_size=batch_size),\n",
        "                    validation_data=(X_test_norm, y_test_cat), callbacks=callbacks,\n",
        "                    steps_per_epoch=len(X_train_norm) / batch_size, epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NuzFke8pyO8r"
      },
      "source": [
        "Recompute the accuracy of your model, does it improve your performances with data augmentation?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsTm86tuyO8r",
        "outputId": "f2f759be-341f-42d2-f736-856ab6fe7e46"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "59/59 [==============================] - 0s 3ms/step\n",
            "10/10 [==============================] - 0s 3ms/step\n",
            "accuracy on train with NN: 0.93045\n",
            "accuracy on test with NN: 0.9015\n"
          ]
        }
      ],
      "source": [
        "# TODO: Compute the accuracy of your model\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "batch_size=1024\n",
        "y_pred_train = to_categorical(model.predict(X_train_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "y_pred_test = to_categorical(model.predict(X_test_norm, batch_size=batch_size).argmax(axis=1), num_classes=10)\n",
        "\n",
        "print('accuracy on train with NN:', accuracy_score(y_pred_train, y_train_cat))\n",
        "print('accuracy on test with NN:', accuracy_score(y_pred_test, y_test_cat))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jOzkdGf7yO8s"
      },
      "source": [
        "You can now try to improve even more your results. For example, add more parameters to your `ImageDataGenerator`, play with some hyperparameters, and so on..."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": true,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {},
      "toc_section_display": true,
      "toc_window_display": false
    },
    "varInspector": {
      "cols": {
        "lenName": 16,
        "lenType": 16,
        "lenVar": 40
      },
      "kernels_config": {
        "python": {
          "delete_cmd_postfix": "",
          "delete_cmd_prefix": "del ",
          "library": "var_list.py",
          "varRefreshCmd": "print(var_dic_list())"
        },
        "r": {
          "delete_cmd_postfix": ") ",
          "delete_cmd_prefix": "rm(",
          "library": "var_list.r",
          "varRefreshCmd": "cat(var_dic_list()) "
        }
      },
      "types_to_exclude": [
        "module",
        "function",
        "builtin_function_or_method",
        "instance",
        "_Feature"
      ],
      "window_display": false
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}